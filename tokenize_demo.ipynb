{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en_core_web_lg==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz (782.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from en_core_web_lg==2.3.1) (2.3.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.11)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.7)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.67.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (68.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.24.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/MLE/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2025.1.31)\n",
      "Building wheels for collected packages: en_core_web_lg\n",
      "  Building wheel for en_core_web_lg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en_core_web_lg: filename=en_core_web_lg-2.3.1-py3-none-any.whl size=782936102 sha256=4121ea7bacc56390b9bff62cbc0ee8c0ec8874c8056d54ca224f1d7c026a98ac\n",
      "  Stored in directory: /Users/yaohuizhang/Library/Caches/pip/wheels/8b/bb/bb/bdc918f4b37d930a1be9ed876e7b2c2ee518a34803d78a248e\n",
      "Successfully built en_core_web_lg\n",
      "Installing collected packages: en_core_web_lg\n",
      "Successfully installed en_core_web_lg-2.3.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# install spacy's large english model\n",
    "! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Processes the input text, splits it into sentences, and further processes each sentence\n",
    "    to extract non-numeric words. It constructs a list of these words for each sentence.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): A string containing multiple sentences.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of lists, where each inner list contains the words from one sentence,\n",
    "          excluding any numeric strings.\n",
    "    \"\"\"\n",
    "    # remove newline characters, this line is not necessary for all cases\n",
    "    # the reason it is included here is because the abstracts in the dataset contain abnormal newline characters\n",
    "    # e.g. Recent works on diffusion models have demonstrated a strong capability for\\nconditioning image generation,\n",
    "    text=text.replace('\\n',' ')\n",
    "    # Initialize an empty list to store the list of words for each sentence\n",
    "    sentence_list=[]\n",
    "    # Process the sentence using the spacy model to extract linguistic features and split into components\n",
    "    doc=nlp(text)\n",
    "    # Iterate over each sentence in the processed text\n",
    "    for sent in doc.sents:\n",
    "        # Extract the words from the sentence\n",
    "        words = re.findall(r'\\b\\w+\\b', sent.text.lower())\n",
    "        # Remove any words that are numeric\n",
    "        words_without_digits=[word for word in words if not word.isdigit()]\n",
    "        # If the list is not empty, append the list of words to the sentence_list\n",
    "        if len(words_without_digits)!=0:\n",
    "            sentence_list.append(words_without_digits)\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['passive', 'acoustic', 'monitoring', 'is', 'used', 'widely', 'in', 'ecology', 'biodiversity', 'and', 'conservation', 'studies'], ['data', 'sets', 'collected', 'via', 'acoustic', 'monitoring', 'are', 'often', 'extremely', 'large', 'and', 'built', 'to', 'be', 'processed', 'automatically', 'using', 'artificial', 'intelligence', 'and', 'machine', 'learning', 'models', 'which', 'aim', 'to', 'replicate', 'the', 'work', 'of', 'domain', 'experts'], ['these', 'models', 'being', 'supervised', 'learning', 'algorithms', 'need', 'to', 'be', 'trained', 'on', 'high', 'quality', 'annotations', 'produced', 'by', 'experts'], ['since', 'the', 'experts', 'are', 'often', 'resource', 'limited', 'a', 'cost', 'effective', 'process', 'for', 'annotating', 'audio', 'is', 'needed', 'to', 'get', 'maximal', 'use', 'out', 'of', 'the', 'data'], ['we', 'present', 'an', 'open', 'source', 'interactive', 'audio', 'data', 'annotation', 'tool', 'neal', 'nature', 'energy', 'audio', 'labeller'], ['built', 'using', 'r', 'and', 'the', 'associated', 'shiny', 'framework', 'the', 'tool', 'provides', 'a', 'reactive', 'environment', 'where', 'users', 'can', 'quickly', 'annotate', 'audio', 'files', 'and', 'adjust', 'settings', 'that', 'automatically', 'change', 'the', 'corresponding', 'elements', 'of', 'the', 'user', 'interface'], ['the', 'app', 'has', 'been', 'designed', 'with', 'the', 'goal', 'of', 'having', 'both', 'expert', 'birders', 'and', 'citizen', 'scientists', 'contribute', 'to', 'acoustic', 'annotation', 'projects'], ['the', 'popularity', 'and', 'flexibility', 'of', 'r', 'programming', 'in', 'bioacoustics', 'means', 'that', 'the', 'shiny', 'app', 'can', 'be', 'modified', 'for', 'other', 'bird', 'labelling', 'data', 'sets', 'or', 'even', 'to', 'generic', 'audio', 'labelling', 'tasks'], ['we', 'demonstrate', 'the', 'app', 'by', 'labelling', 'data', 'collected', 'from', 'wind', 'farm', 'sites', 'across', 'ireland']]\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "text=\"\"\"\"Passive acoustic monitoring is used widely in ecology, biodiversity, and\\nconservation studies. \n",
    "Data sets collected via acoustic monitoring are often\\nextremely large and built to be processed automatically using Artificial\\nIntelligence and Machine learning models, \n",
    "which aim to replicate the work of\\ndomain experts. These models, being supervised learning algorithms, need to be\\ntrained on high quality annotations produced by experts. \n",
    "Since the experts are\\noften resource-limited, a cost-effective process for annotating audio is needed\\nto get maximal use out of the data. \n",
    "We present an open-source interactive audio\\ndata annotation tool, NEAL (Nature+Energy Audio Labeller). \n",
    "Built using R and\\nthe associated Shiny framework, the tool provides a reactive environment where\\nusers can quickly annotate audio files and adjust settings that automatically\\nchange the corresponding elements of the user interface. \n",
    "The app has been\\ndesigned with the goal of having both expert birders and citizen scientists\\ncontribute to acoustic annotation projects. \n",
    "The popularity and flexibility of R\\nprogramming in bioacoustics means that the Shiny app can be modified for other\\nbird labelling data sets, or even to generic audio labelling tasks. \n",
    "We\\ndemonstrate the app by labelling data collected from wind farm sites across\\nIreland.\\n'\"\"\"\n",
    "print(tokenize(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
